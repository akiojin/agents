# 要件定義書

## プロジェクト概要

**プロジェクト名**: @akiojin/agents

**ビジョン**: オープンソースで完全無料の自律型コーディングエージェント。ローカルLLMとクラウドLLMを自由に選択でき、MCPツールによる無限の拡張性を持つ。

## 背景と目的

### 解決したい課題

- Claude CodeやGitHub Copilotなどの既存ツールは有料（月額$20以上）
- 既存のOSSツール（Aider、Continue.dev等）は自律性が低い
- エンタープライズ環境ではセキュリティ上の理由でクラウドLLMが使用できない
- 単一のLLMプロバイダーに依存するリスク

### プロジェクトの目的

1. **完全無料**で高機能なコーディングエージェントの提供
2. **ローカルLLM対応**によるプライバシー保護とオフライン動作
3. **高度な自律性**によるアプリケーション全体の構築
4. **並列処理**による開発速度の向上

## 機能要件

### コア機能

#### 1. 自律的コード生成

- アプリケーション全体を構築可能なレベルの自律性
- エラーの自動検出と修正機能
- タスクの自動分解と実行計画の策定
- 並列実行可能なタスクの自動識別

#### 2. マルチLLMプロバイダー対応

- **ローカルLLM**
  - GPT-OSS (gpt-oss-20b/120b)
  - LM Studio経由のモデル
  - Ollama対応モデル
- **クラウドLLM**
  - OpenAI (GPT-4, GPT-3.5)
  - Anthropic (Claude 3)
  - Google (Gemini)
- 動的なプロバイダー切り替え機能
- タスクに応じた最適なモデル選択

#### 3. MCP (Model Context Protocol) 対応

- Serena MCPツール（コード解析・編集）の標準搭載
- カスタムMCPツールの追加機能
- 並列ツール実行によるパフォーマンス向上
- プラグイン形式での機能拡張

#### 4. CLI機能

- **インタラクティブモード**: 対話型の開発体験
- **バッチモード**: スクリプトからの自動実行
- リアルタイムの進捗表示
- 詳細なログ出力とデバッグ情報

#### 5. 並列処理機能

- 独立したタスクの並列実行
- ファイル作成・編集の並列化
- 依存関係の自動解析
- 競合状態の検出と回避

### 実行環境

#### Node.js環境での実行

```bash
# グローバルインストール
npm install -g @akiojin/agents

# プロジェクトディレクトリで実行
agents

# または直接実行
npx @akiojin/agents
```

**必要要件:**
- Node.js 20.0.0以上
- npm または yarn
- Docker（オプション、推奨）

#### 実行モード

```bash
# インタラクティブモード（デフォルト）
@akiojin/agents

# バッチモード
@akiojin/agents --task "Todoアプリを作成"

# 設定ファイル指定
@akiojin/agents --config ./agents.config.json

# LLMプロバイダー指定
@akiojin/agents --provider local --model gpt-oss-20b
```

## 非機能要件

### パフォーマンス

- 並列処理により従来の3-5倍の処理速度
- 起動時間: 2秒以内（Node.jsランタイム）
- メモリ使用量: 最大2GB（ローカルLLM除く）
- レスポンス時間: 初回応答まで3秒以内

### 拡張性

- MCPプロトコルによる無限の機能拡張
- プラグインアーキテクチャ
- カスタムツールのホットリロード対応
- APIファーストの設計

### 可搬性

- クロスプラットフォーム対応（Windows/Mac/Linux）
- Docker対応
- CI/CD環境での実行サポート
- 環境変数による設定管理

### セキュリティ

- ローカル実行によるデータプライバシー保護
- APIキーの安全な管理
- サンドボックス環境でのコード実行
- 監査ログの出力

### 透明性

- 思考過程の可視化
- プロンプトの公開
- デバッグモードでの詳細情報表示
- オープンソース（MITライセンス）

## 技術仕様

### ランタイムとフレームワーク

```yaml
runtime: Node.js v20.0+
language: TypeScript 5.3+
framework:
  - Base: Gemini CLI (Google)
  - CLI: Commander.js
  - UI: Terminal rendering (Gemini CLI)
package_manager: npm / yarn
```

### 依存関係

```yaml
core:
  - '@anthropic-ai/mcp': MCPプロトコル実装
  - 'serena-mcp': コード解析・編集ツール
  - 'langchain': LLMオーケストレーション

llm_providers:
  - 'openai': OpenAI API
  - '@anthropic-ai/sdk': Claude API
  - '@google/generative-ai': Gemini API
  - 'ollama': ローカルLLM

utilities:
  - 'chalk': ターミナル出力
  - 'ora': スピナー・プログレス表示
  - 'winston': ロギング
```

### アーキテクチャパターン

- **ReAct Pattern**: 推論と行動の繰り返し
- **Task Queue System**: タスクの管理と実行
- **Event-Driven Architecture**: 非同期処理
- **Plugin Architecture**: 拡張可能な設計

## 制約事項

### 技術的制約

- Node.js 20.0.0以上が必要
- Gemini CLIベースのアーキテクチャ制約
- ローカルLLMの実行には16GB以上のRAM推奨
- GPUはオプション（あれば高速化）

### 運用上の制約

- 初期バージョンは英語と日本語のみ対応
- ローカルLLMのモデルサイズは最大50GB
- 同時実行タスク数は最大10個

## 成功基準

### 定量的指標

- アプリケーション全体を60分以内で構築
- 並列処理により3倍以上の高速化
- 90%以上のタスク成功率
- 月間1000人以上のアクティブユーザー

### 定性的指標

- Claude Codeと同等以上の自律性
- 直感的で使いやすいインターフェース
- 活発なOSSコミュニティの形成
- エンタープライズでの採用事例

## リスクと対策

### 技術的リスク

| リスク                  | 影響度 | 対策                                      |
| ----------------------- | ------ | ----------------------------------------- |
| ローカルLLMの性能不足   | 高     | GPT-OSSの採用、クラウドへのフォールバック |
| MCPプロトコルの仕様変更 | 中     | アダプター層の実装、バージョン管理        |
| 並列処理の競合状態      | 中     | ロック機構、トランザクション管理          |

### ビジネスリスク

| リスク                   | 影響度 | 対策                           |
| ------------------------ | ------ | ------------------------------ |
| 既存ツールとの差別化不足 | 高     | 独自機能の開発、UXの向上       |
| コミュニティ形成の失敗   | 中     | ドキュメント充実、サポート体制 |
| メンテナンス負荷         | 低     | 自動テスト、CI/CD整備          |

## 今後の展開

### 短期目標（3ヶ月）

- MVP版のリリース
- 基本的なMCPツール実装
- ドキュメント整備

### 中期目標（6ヶ月）

- マルチエージェント対応
- エンタープライズ機能
- プラグインエコシステム

### 長期目標（1年）

- AIエージェント間の協調
- ビジュアルプログラミング対応
- SaaS版の提供（オプション）
